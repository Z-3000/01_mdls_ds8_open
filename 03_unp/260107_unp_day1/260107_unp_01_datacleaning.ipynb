{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d5e9fa9",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Data cleaning - 타이타닉 데이터 다루기\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b62edf",
   "metadata": {},
   "source": [
    "---\n",
    "## 1-1. 들어가며\n",
    "### 학습 내용\n",
    "- 판다스를 사용한 데이터 탐색, 불필요한 컬럼 및 결측치 처리, 이상치와 중복 데이터 처리, 텍스트 및 날짜/시간 데이터 처리를 통해 데이터 정제의 기본을 배웁니다.\n",
    "### 학습 목표\n",
    "1. 결측치를 처리할 수 있다.\n",
    "2. 이상치를 판단하고 처리할 수 있다.    \n",
    "3. 시간 데이터 및 텍스트형 데이터를 자유롭게 변환할 수 있다.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddab06fc",
   "metadata": {},
   "source": [
    "---\n",
    "## 1-2. 파이썬으로 데이터 둘러보기\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31328317",
   "metadata": {},
   "source": [
    "### 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48d9194b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/260107_unp_day1\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "959dce16",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/aiffel/data/titanic.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_90/1820393616.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#  기존 타이타닉 데이터 셋을 살짝변경함 (오타 등...)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/aiffel/data/titanic.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/aiffel/data/titanic.csv'"
     ]
    }
   ],
   "source": [
    "# pandas 라이브러리 임포트 후 파일 불러오기\n",
    "#  기존 타이타닉 데이터 셋을 살짝변경함 (오타 등...)\n",
    "import pandas as pd  \n",
    "pd.read_csv('/aiffel/data/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1badf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas 데이터 프레임을 data라는 변수에 지정 \n",
    "data = pd.read_csv('/aiffel/data/titanic.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb39f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[추가] 중복행 확인\n",
    "data[data.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e731b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#중복행 삭제 후 data 변수에 입력\n",
    "data = data.drop_duplicates()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f0c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음 10줄\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7271ee7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 10줄\n",
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eec1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 컬럼에 대한 결측치, 데이터타입 등의 정보 제공 \n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05177112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 타입이 숫자인 컬럼의 통계치 제공\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0074cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판다스 시리즈..열람...컬럼 2개 이상은 불러올 수 없음\n",
    "# 지정한 컬럼의 정보..?\n",
    "data['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbd796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판다스 시리즈..열람...컬럼 2개 이상 불러오려면 대괄호로 리스트형식으로 묶어줘야함 \n",
    "data[['Name','Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84130bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판다스 데이터프레임을 ->판다스 시리즈로\n",
    "pd.DataFrame(data['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ccc222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판다스 시리즈를 -> 판다스 데이터 프레임으로\n",
    "pd.Series(pd.DataFrame(data['Name'])['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9098bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 넘파이 -> 가독성은 좋지 않지만 연산 속도가 빠름 \n",
    "# 연산결과가 넘파이인 경우가 많으므로 읽고 변환할 수 있어야 함 \n",
    "import numpy as np\n",
    "np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e690042",
   "metadata": {},
   "source": [
    "---\n",
    "## 1-3. 불필요한 컬럼 삭제 (Dropping columns), 누락된 결측치 처리 (Missing values)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dbc3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "pd.read_csv('/aiffel/data/titanic.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afbff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼제거 \n",
    "# 판다스 데이터프레임에서 drop 함수를 쓸 때는 축을 바꿔줘야함 (axis=1) 없으면 행기준으로 데이터 취급함\n",
    "# 해당함수는 뷰에서만 컬럼을 없애주므로 데이터를 덮어 쓰는것은 아님 덮어쓰기 위해서는 (inplace=True) 추가 필요\n",
    "data.drop('Name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4533f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 함수로 행 삭제 \n",
    "data.drop(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 함수괄호 안에는 두개의 오브젝트를 넣을 수 없으므로 리스트(대괄호)로 잡아줘야함 \n",
    "# data.drop('Name', 'Pclass', axis=1) -> 에러 발생 \n",
    "data.drop(['Name', 'Pclass'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9affc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc 함수로 행의 이름을 이용하여 필요한 열 불러오기 , 마찬가지로 리스트(대괄호)로 잡아줘야함 \n",
    "data.loc[[4,5,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becf79f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc 함수 -> loc 함수랑 겉보기에 출력값은 같음\n",
    "# 행의 순서를 기반으로 데이터 불러옴 (대괄호 안의 값은 항상 숫자가 들어가야함)\n",
    "data.iloc[[4,5,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3dc9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼별 결측치 숫자 확인 \n",
    "# 데이터 프레임에서 .sum(), mean() 을 붙여주면 각 컬럼의 통계치를 볼 수 있음 \n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fd687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb131e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Age'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cdbc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_na_index=data[data['Age'].isna()].index\n",
    "Embarked_na_index=data[data['Embarked'].isna()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26006317",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[Embarked_na_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a309cb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 행 확인 \n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d7a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# null 값인 모든 행 삭제\n",
    "data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9842df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 컬럼의 null 값인 행만 삭제\n",
    "# data.dropna(subset = ['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bf97c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# null 값을 특정 값으로 일괄 채우기 \n",
    "# data.fillna(999)\n",
    "\n",
    "# Age 컬럼의 null 값을 통계값으로 채우기\n",
    "# data['Age'] = data['Age'].fillna(data['Age'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150d5190",
   "metadata": {},
   "source": [
    "---\n",
    "## 1-4. 이상치 탐지 및 처리 (Outliers)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b311e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분포 검토 결과 Age, SibSp 컬럼 을 더 볼 필요가 있음 \n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e77f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d32c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SibSp'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7028d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 시각화 (히스토그램 및 산점도 등..)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.histplot(data['SibSp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200f99e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a8174d",
   "metadata": {},
   "outputs": [],
   "source": [
    " sns.scatterplot(x= data.index, y= data['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbef04e9",
   "metadata": {},
   "outputs": [],
   "source": [
    " sns.scatterplot(x= data.index, y= data['SibSp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c016f5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0a4523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age 100 이상 삭제  (이상치로 간주)\n",
    "data=data[ data ['Age'] <= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f681ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8afc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_func(x):\n",
    "    if x > 80:\n",
    "        return 80\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5bfd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼의 값마다 함수 적용하는 방법 \n",
    "data['Age'] = data['Age'].apply(age_func)\n",
    "data['Age'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441bc02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_age_func(x):\n",
    "    if x > 70:\n",
    "        return 70\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c8ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 두 함수 같은 결과 (람다냐 선언함수냐 차이 )\n",
    "# data['Age'].apply(new_age_func)\n",
    "data['Age'].apply(lambda x: 70 if x > 70 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c84b0d8",
   "metadata": {},
   "source": [
    "---\n",
    "## 1-5. 중복 데이터 처리 및 데이터 형태 변환처리(Removing duplicate data, apply, map, replace, rename)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85438663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제한 데이터 대처하는 법 \n",
    "# 데이터 호출 블럭으로 가서 함수 수행 \n",
    "# data .drop_duplicates()\n",
    "# 확인 \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51c4853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼명 바꾸기 , 컬럼 지정할때는  axis = 1 추가\n",
    "data.rename({'Gendr':'Gender'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b0165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼명 바꾸기 , 행이름 바꾸기 \n",
    "data.rename({0:'a'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19f7674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 함수 : 여러개의 특정 값을 한번에 바꿈\n",
    "data.replace({'S':'Southampton'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f44c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map 함수 : 여러개의 특정 값을 한번에 바꿈\n",
    "# replace 함수와 다른점 1. 데이터 프레임에만 적용 가능 2. .각각의 라인별 함수를 매핑할 수 있음 \n",
    "data['Embarked'].replace({'S':'Southampton'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79c84c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map / replace / apply 정리 \n",
    "#  공통: “규칙(함수/매핑)”로 값을 변환해 새 Series/컬럼을 만든다.\n",
    "\n",
    "# map:\n",
    "#   - 대상: Series(단일 컬럼)\n",
    "#   - 방식: 값 → 값 매핑(dict/함수)\n",
    "#   - 특징: 매핑에 없는 값은 NaN이 될 수 있음(누락을 드러냄)\n",
    "\n",
    "#  replace:\n",
    "#   - 대상: Series/DataFrame\n",
    "#   - 방식: 특정 값(들)만 찾아서 치환\n",
    "#   - 특징: 지정 안 한 값은 보통 그대로 유지(부분 교정에 강함)\n",
    "\n",
    "#  apply:\n",
    "#   - 대상: Series/DataFrame\n",
    "#   - 방식: 함수 적용(DF는 보통 행/열 단위로 적용)\n",
    "#   - 특징: 여러 컬럼을 엮는 계산/조건 로직에 적합(단순 치환엔 과할 수 있음)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5d8e73",
   "metadata": {},
   "source": [
    "---\n",
    "## 1-6. 텍스트 처리 (Text handling)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e50300",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d935a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124a18da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#샘플 텍스트 데이터로 실습 해 보기 \n",
    "sample_txt = 'A/5 21171'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3acead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자로 인덱싱 \n",
    "sample_txt[:3]\n",
    "sample_txt[4:]\n",
    "sample_txt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1befae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대소문자 변경 \n",
    "sample_txt.upper() # 대문자 변경 \n",
    "sample_txt.lower()  # 소문자 변경 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e18dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열 나누기\n",
    "sample_txt.split() # 띄어쓰기 기준으로 나누고 리스트로 만들어줌 \n",
    "sample_txt.split(' ') # 띄어쓰기 기준으로 나누고 리스트로 만들어줌 \n",
    "sample_txt.split('/') # / 기준으로 나누기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e509b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열 나누기 + 인덱싱 \n",
    "sample_txt.split()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6402f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불필요한 앞, 뒷부분 띄어쓰기 삭제\n",
    "new_txt=' A/5 21171'\n",
    "new_txt\n",
    "\n",
    "new_txt.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb46501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판다스 시리즈에서 인덱스를 쓰면 그에 해당하는 열을 불러옴 \n",
    "data['Ticket'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8344a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .str을 써주면 함수로 인식하여 사용가능 \n",
    "data['Ticket'].str[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d50ae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 티켓 번호만 뽑고 싶은데, 인덱싱결과 번호만 있는 데이터의 인덱싱 값이 일정하지 않음 \n",
    "data['Ticket'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574e8f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .split()결과물이 리스트로 되었는데 이를 각각의 컬럼으로 만들어주기 (expand = True)\n",
    "data['Ticket'].str.split(expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7d8358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해결을 위해 expand 쓰지않고 람다함수를 사용해서 인덱싱 , 별도 컬럼 new_ticket으로 저장 \n",
    "data['new_ticket']=data['Ticket'].str.split().apply(lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734d6843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_ticket 데이터 타입이 object\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b509eb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_ticket 데이터 타입 수정 -> 숫자말고 문자열이 섞여 있어서 에러발생 \n",
    "data['new_ticket'] .astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074f5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_ticket 데이터 타입 확인을 위한 함수 (샘플로 실습)\n",
    "txt_a = '123'\n",
    "txt_b = 'abc'\n",
    "txt_c = '12a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9327e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .isdigit() -> 숫자면  TRUE 반환\n",
    "txt_a.isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0be8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞에 ~ 기호 쓰면  True/False 반전 (문자열인 데이터 필터링)\n",
    "data[~data['new_ticket'].str.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe63fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자라고 걸러진 결과에 대해서 특정 숫자를 매핑하여 데이터 타입 변경 \n",
    "data['new_ticket'] = data['new_ticket'].replace({'LINE':'99999999'})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ba28f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수정여부 확인 후 데이터 타입 변경 \n",
    "data[~data['new_ticket'].str.isdigit()]\n",
    "data['new_ticket'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dea5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 방법 : 판다스가 데이터 타입 인식하여 자동으로 알아서 바꿔줌 \n",
    "data['new_ticket'] = pd.to_numeric(data['new_ticket'])\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b32b693",
   "metadata": {},
   "source": [
    "---\n",
    "## 1-7. 날짜 및 시간 데이터 처리 (Datetime)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65432980",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# 년월일시 양식은 검색하면 나옴 \n",
    "sample_date=datetime.strptime('2023-01-01','%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c25e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 년월일시 양식 변경 \n",
    "datetime.strftime(sample_date, '%y-%b-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c04d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#년월일시 추출 \n",
    "sample_date.year\n",
    "sample_date.month\n",
    "sample_date.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0862bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_date = datetime.strptime('2023-05-05','%Y-%m-%d')\n",
    "next_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096a979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_date - next_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ad3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticket_date 컬럼의 데이터타입을 변경\n",
    "data['ticket_date'] = pd.to_datetime(data['ticket_date'])\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a688ef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ticket_date'].dt.year\n",
    "data['ticket_date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d316960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 티켓 구매 날짜와 사고날짜 차이 계산 (buy_before컬럼은 연산이 안되서 가공 필요)\n",
    "acc = datetime.strptime('1912-04-15', '%Y-%m-%d')\n",
    "data['buy_before'] = acc - data['ticket_date']\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1decddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buy_before 컬럼 데이터 타입을 int 로 수정 \n",
    "data['buy_before'] = data['buy_before'].dt.days\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f35ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['buy_before'] + 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a3940e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
